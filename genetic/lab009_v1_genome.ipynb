{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Neuroevolution (GA) Multi-Seed Training with Best-Model Selection\n",
    "\n",
    "This notebook trains a Genetic Algorithm across multiple seeds, with:\n",
    "- **Best genome tracking** per generation (saved as `.npy`)\n",
    "- **Deterministic evaluation** of best genomes (20 episodes per seed)\n",
    "- **Comparable metrics** to the DQN & PPO notebook (lab009_v1)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, random, time\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import gymnasium as gym\n",
    "import imageio.v2 as imageio\n",
    "from IPython.display import Image, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add src/ to path so we can import the GA modules\n",
    "SRC_DIR = os.path.join(os.path.dirname(os.path.abspath(\"__file__\")), \"src\")\n",
    "if SRC_DIR not in sys.path:\n",
    "    sys.path.insert(0, SRC_DIR)\n",
    "\n",
    "from src.evolution.genetic_algorithm import GeneticAlgorithm\n",
    "from src.evolution.neural_network import NeuralNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Configuration\n",
    "\n",
    "SEED_LIST = [42, 123, 999]\n",
    "\n",
    "NOTEBOOK_DIR = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "GYMNASIUM_MODEL = \"LunarLander-v3\"\n",
    "\n",
    "WIND_ENABLED = False\n",
    "\n",
    "# GA hyperparameters\n",
    "INPUT_SIZE = 8\n",
    "HIDDEN1_SIZE = 10\n",
    "HIDDEN2_SIZE = 10\n",
    "OUTPUT_SIZE = 4\n",
    "\n",
    "POPULATION_SIZE = 50\n",
    "MUTATION_RATE = 0.05\n",
    "GENERATIONS = 5000\n",
    "EVAL_SEEDS_PER_GEN = 3  # seeds used to evaluate each genome during training\n",
    "\n",
    "# Evaluation\n",
    "EVALUATION_EPISODES = 20\n",
    "\n",
    "# Parallelization\n",
    "MAX_WORKERS = 20\n",
    "\n",
    "print(f\"Seeds: {SEED_LIST}\")\n",
    "print(f\"Wind enabled: {WIND_ENABLED}\")\n",
    "print(f\"Generations: {GENERATIONS}\")\n",
    "print(f\"Population size: {POPULATION_SIZE}\")\n",
    "print(f\"Mutation rate: {MUTATION_RATE}\")\n",
    "print(f\"Eval seeds per generation: {EVAL_SEEDS_PER_GEN}\")\n",
    "print(f\"Evaluation episodes per seed: {EVALUATION_EPISODES}\")\n",
    "print(f\"Max workers: {MAX_WORKERS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Python:\", sys.version.split()[0])\n",
    "print(\"NumPy:\", np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment inspection\n",
    "env_tmp = gym.make(GYMNASIUM_MODEL)\n",
    "\n",
    "print(\"Observation space:\", env_tmp.observation_space)\n",
    "print(\"Action space:\", env_tmp.action_space)\n",
    "\n",
    "obs, info = env_tmp.reset()\n",
    "print(\"Initial observation:\", obs)\n",
    "\n",
    "env_tmp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_all_seeds(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "\n",
    "def evaluate_genome_deterministic(genome, n_episodes, seed=None):\n",
    "    \"\"\"\n",
    "    Evaluate a genome deterministically over n_episodes.\n",
    "    No early termination. Returns list of per-episode rewards.\n",
    "    \"\"\"\n",
    "    nn = NeuralNetwork(INPUT_SIZE, HIDDEN1_SIZE, HIDDEN2_SIZE, OUTPUT_SIZE, genome)\n",
    "    env = gym.make(GYMNASIUM_MODEL, enable_wind=WIND_ENABLED)\n",
    "    rewards = []\n",
    "\n",
    "    for ep in range(n_episodes):\n",
    "        ep_seed = seed + ep if seed is not None else None\n",
    "        obs, _ = env.reset(seed=ep_seed)\n",
    "        total_reward = 0.0\n",
    "        done = False\n",
    "\n",
    "        while not done:\n",
    "            output = nn.forward(obs)\n",
    "            action = np.argmax(output)\n",
    "            obs, reward, terminated, truncated, _ = env.step(action)\n",
    "            done = terminated or truncated\n",
    "            total_reward += float(reward)\n",
    "\n",
    "        rewards.append(total_reward)\n",
    "\n",
    "    env.close()\n",
    "    return rewards\n",
    "\n",
    "\n",
    "def record_genome_gif(genome, seed, output_path):\n",
    "    \"\"\"\n",
    "    Record a single episode GIF of a genome.\n",
    "    \"\"\"\n",
    "    nn = NeuralNetwork(INPUT_SIZE, HIDDEN1_SIZE, HIDDEN2_SIZE, OUTPUT_SIZE, genome)\n",
    "    env = gym.make(GYMNASIUM_MODEL, render_mode=\"rgb_array\", enable_wind=WIND_ENABLED)\n",
    "    obs, _ = env.reset(seed=seed)\n",
    "    frames = []\n",
    "    done = False\n",
    "\n",
    "    while not done:\n",
    "        frames.append(env.render())\n",
    "        output = nn.forward(obs)\n",
    "        action = np.argmax(output)\n",
    "        obs, reward, terminated, truncated, _ = env.step(action)\n",
    "        done = terminated or truncated\n",
    "\n",
    "    env.close()\n",
    "    imageio.mimsave(output_path, frames, fps=30, loop=0)\n",
    "    return output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop: GA x seeds\n",
    "\n",
    "from IPython.display import display as ipy_display\n",
    "\n",
    "training_results = {}   # {seed: {\"best\": [], \"avg\": [], \"worst\": []}}\n",
    "training_times = {}     # {seed: seconds}\n",
    "best_genomes = {}       # {seed: genome}\n",
    "best_genome_paths = {}  # {seed: path}\n",
    "total_env_steps = {}    # {seed: int}\n",
    "eval_histories = {}     # {seed: list of eval dicts}\n",
    "\n",
    "CHART_UPDATE_FREQ = 100\n",
    "EVAL_FREQ_GENS = 100\n",
    "EVAL_N_EPISODES = 20\n",
    "SOLVED_THRESHOLD = 200\n",
    "\n",
    "for seed in SEED_LIST:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"GA | Seed {seed}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "\n",
    "    # Create timestamped run directory\n",
    "    run_timestamp = datetime.now().strftime(\"%Y-%m-%d_%H_%M_%S\")\n",
    "    run_dir = os.path.join(NOTEBOOK_DIR, \"../models\", \"ga\", run_timestamp)\n",
    "    os.makedirs(run_dir, exist_ok=True)\n",
    "\n",
    "    set_all_seeds(seed)\n",
    "\n",
    "    ga = GeneticAlgorithm(\n",
    "        INPUT_SIZE, HIDDEN1_SIZE, HIDDEN2_SIZE, OUTPUT_SIZE,\n",
    "        POPULATION_SIZE, MUTATION_RATE, render=False, max_workers=MAX_WORKERS,\n",
    "        generations=GENERATIONS\n",
    "    )\n",
    "\n",
    "    best_fitness_history = []\n",
    "    avg_fitness_history = []\n",
    "    worst_fitness_history = []\n",
    "    env_steps = 0\n",
    "    sorted_population = []\n",
    "\n",
    "    # Best model tracking (matches DQN/PPO two-tier selection)\n",
    "    best_combined_score = -np.inf\n",
    "    best_genome = np.array([])\n",
    "    best_eval_mean = 0.0\n",
    "    best_eval_std = np.inf\n",
    "    best_eval_success = 0.0\n",
    "    best_gen = 0\n",
    "    any_solved = False\n",
    "    eval_history = []\n",
    "\n",
    "    plot_handle = None\n",
    "    stats_handle = None\n",
    "    eval_handle = None\n",
    "\n",
    "    t_start = time.time()\n",
    "\n",
    "    for gen in range(GENERATIONS):\n",
    "        sorted_population = ga.evaluate_population(gen)\n",
    "        fitness_values = [fitness for _, fitness in sorted_population]\n",
    "        best_fitness = fitness_values[0]\n",
    "        worst_fitness = fitness_values[-1]\n",
    "        avg_fitness = sum(fitness_values) / len(fitness_values)\n",
    "\n",
    "        best_fitness_history.append(best_fitness)\n",
    "        avg_fitness_history.append(avg_fitness)\n",
    "        worst_fitness_history.append(worst_fitness)\n",
    "\n",
    "        env_steps += POPULATION_SIZE * EVAL_SEEDS_PER_GEN * 300\n",
    "\n",
    "        # Periodic deterministic evaluation of generation's best genome\n",
    "        if (gen + 1) % EVAL_FREQ_GENS == 0:\n",
    "            candidate_genome = sorted_population[0][0]\n",
    "            eval_rewards = evaluate_genome_deterministic(\n",
    "                candidate_genome, EVAL_N_EPISODES, seed=seed\n",
    "            )\n",
    "            eval_mean = np.mean(eval_rewards)\n",
    "            eval_std = np.std(eval_rewards)\n",
    "            eval_success = np.sum(np.array(eval_rewards) >= SOLVED_THRESHOLD) / len(eval_rewards) * 100\n",
    "            combined_score = eval_mean - eval_std\n",
    "            is_solved = eval_mean >= SOLVED_THRESHOLD\n",
    "\n",
    "            eval_history.append({\n",
    "                \"generation\": gen + 1,\n",
    "                \"mean\": eval_mean,\n",
    "                \"std\": eval_std,\n",
    "                \"success\": eval_success,\n",
    "                \"score\": combined_score,\n",
    "                \"solved\": is_solved,\n",
    "            })\n",
    "\n",
    "            # Two-tier best model selection (matches DQN/PPO logic)\n",
    "            save_new_best = False\n",
    "            if is_solved:\n",
    "                if not any_solved:\n",
    "                    save_new_best = True\n",
    "                    any_solved = True\n",
    "                elif combined_score > best_combined_score:\n",
    "                    save_new_best = True\n",
    "            elif not any_solved:\n",
    "                if combined_score > best_combined_score:\n",
    "                    save_new_best = True\n",
    "\n",
    "            solved_tag = \" [SOLVED]\" if is_solved else \"\"\n",
    "            eval_text = (\n",
    "                f\"Eval @ Gen {gen + 1} | \"\n",
    "                f\"Reward: {eval_mean:.2f} +/- {eval_std:.2f}{solved_tag} | \"\n",
    "                f\"Success: {eval_success:.0f}% | \"\n",
    "                f\"Score (mean-std): {combined_score:.2f} | \"\n",
    "                f\"Best: {best_combined_score:.2f}\"\n",
    "            )\n",
    "\n",
    "            if save_new_best:\n",
    "                eval_text += \" >> New best genome!\"\n",
    "                best_combined_score = combined_score\n",
    "                best_eval_mean = eval_mean\n",
    "                best_eval_std = eval_std\n",
    "                best_eval_success = eval_success\n",
    "                best_gen = gen + 1\n",
    "                best_genome = candidate_genome.copy()\n",
    "                np.save(os.path.join(run_dir, \"best_genome.npy\"), best_genome)\n",
    "\n",
    "            if eval_handle is None:\n",
    "                eval_handle = ipy_display(eval_text, display_id=True)\n",
    "            else:\n",
    "                eval_handle.update(eval_text)\n",
    "\n",
    "        if (gen + 1) % CHART_UPDATE_FREQ == 0:\n",
    "            recent_avg = np.mean(avg_fitness_history[-100:])\n",
    "            stats_text = (\n",
    "                f\"Generation {gen + 1} | \"\n",
    "                f\"Best: {best_fitness:>8.2f} | \"\n",
    "                f\"Avg: {avg_fitness:>8.2f} | \"\n",
    "                f\"Worst: {worst_fitness:>8.2f} | \"\n",
    "                f\"Best Score: {best_combined_score:>8.2f} | \"\n",
    "                f\"Recent Avg(100): {recent_avg:.1f} | \"\n",
    "                f\"MR: {ga.mutation_rate:.4f}\"\n",
    "            )\n",
    "            if stats_handle is None:\n",
    "                stats_handle = ipy_display(stats_text, display_id=True)\n",
    "            else:\n",
    "                stats_handle.update(stats_text)\n",
    "\n",
    "            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 4))\n",
    "\n",
    "            ax1.plot(best_fitness_history, alpha=0.3, color='blue')\n",
    "            ax1.plot(avg_fitness_history, alpha=0.3, color='orange')\n",
    "            window = min(50, len(best_fitness_history))\n",
    "            rolling_best = pd.Series(best_fitness_history).rolling(window).mean()\n",
    "            rolling_avg = pd.Series(avg_fitness_history).rolling(window).mean()\n",
    "            ax1.plot(rolling_best, color='blue', linewidth=2, label='Best (rolling)')\n",
    "            ax1.plot(rolling_avg, color='orange', linewidth=2, label='Avg (rolling)')\n",
    "            ax1.axhline(y=200, color='red', linestyle='--', alpha=0.5)\n",
    "            ax1.set_title(f\"Fitness - Gen {gen + 1}\")\n",
    "            ax1.set_xlabel(\"Generation\")\n",
    "            ax1.set_ylabel(\"Fitness\")\n",
    "            ax1.legend(fontsize=8)\n",
    "            ax1.grid(True, alpha=0.3)\n",
    "\n",
    "            success = np.array(best_fitness_history) >= 200\n",
    "            rolling_success = pd.Series(success.astype(float)).rolling(window).mean() * 100\n",
    "            ax2.plot(rolling_success, color='green', linewidth=2)\n",
    "            ax2.axhline(y=100, color='green', linestyle=':', alpha=0.4)\n",
    "            ax2.set_title(f\"Success Rate (best >= 200)\")\n",
    "            ax2.set_xlabel(\"Generation\")\n",
    "            ax2.set_ylabel(\"Success Rate (%)\")\n",
    "            ax2.set_ylim(-5, 105)\n",
    "            ax2.grid(True, alpha=0.3)\n",
    "\n",
    "            plt.tight_layout()\n",
    "\n",
    "            if plot_handle is None:\n",
    "                plot_handle = ipy_display(fig, display_id=True)\n",
    "            else:\n",
    "                plot_handle.update(fig)\n",
    "            plt.close(fig)\n",
    "\n",
    "        ga.next_generation(sorted_population)\n",
    "\n",
    "    t_elapsed = time.time() - t_start\n",
    "\n",
    "    # Save final genome (best of last generation)\n",
    "    final_genome = sorted_population[0][0]\n",
    "    final_path = os.path.join(run_dir, f\"lab009_ga_{seed}.npy\")\n",
    "    np.save(final_path, final_genome)\n",
    "\n",
    "    # Save eval log (matches DQN/PPO evaluations.npz format)\n",
    "    eval_log_dir = os.path.join(run_dir, \"eval_log\")\n",
    "    os.makedirs(eval_log_dir, exist_ok=True)\n",
    "    if eval_history:\n",
    "        np.savez(\n",
    "            os.path.join(eval_log_dir, \"evaluations\"),\n",
    "            generations=np.array([e[\"generation\"] for e in eval_history]),\n",
    "            means=np.array([e[\"mean\"] for e in eval_history]),\n",
    "            stds=np.array([e[\"std\"] for e in eval_history]),\n",
    "            scores=np.array([e[\"score\"] for e in eval_history]),\n",
    "            success_rates=np.array([e[\"success\"] for e in eval_history]),\n",
    "        )\n",
    "\n",
    "    # Save fitness history\n",
    "    history_path = os.path.join(run_dir, f\"fitness_history_seed{seed}.npz\")\n",
    "    np.savez(history_path,\n",
    "             best=best_fitness_history,\n",
    "             avg=avg_fitness_history,\n",
    "             worst=worst_fitness_history)\n",
    "\n",
    "    training_results[seed] = {\n",
    "        \"best\": best_fitness_history,\n",
    "        \"avg\": avg_fitness_history,\n",
    "        \"worst\": worst_fitness_history,\n",
    "    }\n",
    "    training_times[seed] = t_elapsed\n",
    "    best_genomes[seed] = best_genome\n",
    "    best_genome_paths[seed] = {\n",
    "        \"run_dir\": run_dir,\n",
    "        \"final\": final_path,\n",
    "        \"best\": os.path.join(run_dir, \"best_genome.npy\"),\n",
    "    }\n",
    "    total_env_steps[seed] = env_steps\n",
    "    eval_histories[seed] = eval_history\n",
    "\n",
    "    print(f\"\\nTraining time: {t_elapsed/60:.1f} min ({t_elapsed:.0f} s)\")\n",
    "    print(f\"Final genome:  {final_path}\")\n",
    "    print(f\"Best genome:   {os.path.join(run_dir, 'best_genome.npy')}\")\n",
    "    print(f\"Eval log:      {eval_log_dir}\")\n",
    "    print(\n",
    "        f\"Best genome stats: \"\n",
    "        f\"Reward: {best_eval_mean:.2f} +/- {best_eval_std:.2f} | \"\n",
    "        f\"Success: {best_eval_success:.0f}% | \"\n",
    "        f\"Score (mean-std): {best_combined_score:.2f} | \"\n",
    "        f\"@ Gen {best_gen}\"\n",
    "    )\n",
    "    print(f\"Estimated env steps: {env_steps:,}\")\n",
    "\n",
    "print(f\"\\nGA: All {len(SEED_LIST)} seeds trained.\")\n",
    "\n",
    "# Training Summary Table\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"BEST MODEL SUMMARY (all seeds)\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "rows = []\n",
    "for seed in SEED_LIST:\n",
    "    # Find the best eval entry for this seed\n",
    "    best_eval = max(eval_histories[seed], key=lambda x: x[\"score\"])\n",
    "    rows.append({\n",
    "        \"Seed\": seed,\n",
    "        \"Mean Reward\": f\"{best_eval['mean']:.2f}\",\n",
    "        \"Std Reward\": f\"{best_eval['std']:.2f}\",\n",
    "        \"Success\": f\"{best_eval['success']:.0f}%\",\n",
    "        \"Score (mean-std)\": f\"{best_eval['score']:.2f}\",\n",
    "        \"@ Generation\": best_eval[\"generation\"],\n",
    "        \"Time (min)\": f\"{training_times[seed]/60:.1f}\",\n",
    "    })\n",
    "\n",
    "print(pd.DataFrame(rows).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Time Summary\n",
    "\n",
    "rows = []\n",
    "for seed in SEED_LIST:\n",
    "    t = training_times[seed]\n",
    "    rows.append({\n",
    "        \"Algorithm\": \"GA\",\n",
    "        \"Seed\": seed,\n",
    "        \"Time (s)\": f\"{t:.0f}\",\n",
    "        \"Time (min)\": f\"{t/60:.1f}\",\n",
    "    })\n",
    "\n",
    "times = list(training_times.values())\n",
    "rows.append({\n",
    "    \"Algorithm\": \"GA\",\n",
    "    \"Seed\": \"Mean\",\n",
    "    \"Time (s)\": f\"{np.mean(times):.0f}\",\n",
    "    \"Time (min)\": f\"{np.mean(times)/60:.1f}\",\n",
    "})\n",
    "\n",
    "print(\"*** TRAINING TIME SUMMARY ***\")\n",
    "print(f\"Generations: {GENERATIONS} | Population: {POPULATION_SIZE} | Workers: {MAX_WORKERS}\")\n",
    "print()\n",
    "print(pd.DataFrame(rows).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per-Seed: Fitness over Generations\n",
    "\n",
    "fig, axes = plt.subplots(1, len(SEED_LIST), figsize=(6 * len(SEED_LIST), 5), sharey=True)\n",
    "if len(SEED_LIST) == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for ax, seed in zip(axes, SEED_LIST):\n",
    "    ax.plot(training_results[seed][\"best\"], alpha=0.7, label=\"Best\")\n",
    "    ax.plot(training_results[seed][\"avg\"], alpha=0.7, label=\"Average\")\n",
    "    ax.plot(training_results[seed][\"worst\"], alpha=0.5, label=\"Worst\")\n",
    "    ax.axhline(y=200, color='red', linestyle='--', alpha=0.5)\n",
    "    ax.set_title(f\"Seed {seed}\")\n",
    "    ax.set_xlabel(\"Generation\")\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.legend(fontsize=8)\n",
    "\n",
    "axes[0].set_ylabel(\"Fitness\")\n",
    "fig.suptitle(\"GA - Fitness over Generations\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregated: Rolling Best Fitness Overlay (all seeds on one chart)\n",
    "\n",
    "seed_colors = list(plt.colormaps[\"tab10\"](range(10)))\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "for i, seed in enumerate(SEED_LIST):\n",
    "    rolling = pd.Series(training_results[seed][\"best\"]).rolling(50).mean()\n",
    "    plt.plot(rolling, color=seed_colors[i], linewidth=2, label=f\"Seed {seed}\")\n",
    "\n",
    "plt.axhline(y=200, color='red', linestyle='--', label='Solved Threshold (200)')\n",
    "plt.title(\"GA Training: Rolling Best Fitness (window=50)\", fontsize=14)\n",
    "plt.xlabel(\"Generation\")\n",
    "plt.ylabel(\"Fitness\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregated: Rolling Average Fitness Overlay (all seeds on one chart)\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "for i, seed in enumerate(SEED_LIST):\n",
    "    rolling = pd.Series(training_results[seed][\"avg\"]).rolling(50).mean()\n",
    "    plt.plot(rolling, color=seed_colors[i], linewidth=2, label=f\"Seed {seed}\")\n",
    "\n",
    "plt.axhline(y=200, color='red', linestyle='--', label='Solved Threshold (200)')\n",
    "plt.title(\"GA Training: Rolling Average Fitness (window=50)\", fontsize=14)\n",
    "plt.xlabel(\"Generation\")\n",
    "plt.ylabel(\"Fitness\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rolling Success Rate over Training (best fitness >= 200)\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "for i, seed in enumerate(SEED_LIST):\n",
    "    success = np.array(training_results[seed][\"best\"]) >= 200\n",
    "    rolling_success = pd.Series(success.astype(float)).rolling(50).mean() * 100\n",
    "    plt.plot(rolling_success, color=seed_colors[i], linewidth=2, label=f\"Seed {seed}\")\n",
    "\n",
    "plt.axhline(y=100, color='green', linestyle=':', alpha=0.4, label='100%')\n",
    "plt.axhline(y=50, color='gray', linestyle=':', alpha=0.4, label='50%')\n",
    "plt.title(\"GA Training: Rolling Success Rate - Best Genome (window=50)\", fontsize=14)\n",
    "plt.xlabel(\"Generation\")\n",
    "plt.ylabel(\"Success Rate (%)\")\n",
    "plt.ylim(-5, 105)\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation: deterministic episodes per seed (best genome)\n",
    "\n",
    "evaluation_results = {}  # {seed: np.array}\n",
    "\n",
    "for seed in SEED_LIST:\n",
    "    print(f\"Evaluating GA seed {seed} (best genome)...\")\n",
    "\n",
    "    set_all_seeds(seed)\n",
    "    genome = best_genomes[seed]\n",
    "\n",
    "    rewards = evaluate_genome_deterministic(genome, EVALUATION_EPISODES, seed=seed)\n",
    "    evaluation_results[seed] = np.array(rewards)\n",
    "\n",
    "    mean_r = np.mean(rewards)\n",
    "    std_r = np.std(rewards)\n",
    "    success = np.sum(np.array(rewards) >= 200) / len(rewards) * 100\n",
    "    print(f\"  Reward: {mean_r:.2f} +/- {std_r:.2f} | Success: {success:.0f}%\")\n",
    "\n",
    "print(f\"\\nEvaluation complete for all seeds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation Summary Table\n",
    "\n",
    "rows = []\n",
    "for seed in SEED_LIST:\n",
    "    r = evaluation_results[seed]\n",
    "    rows.append({\n",
    "        \"Seed\": seed,\n",
    "        \"Mean Reward\": f\"{np.mean(r):.2f}\",\n",
    "        \"Std Dev\": f\"{np.std(r):.2f}\",\n",
    "        \"Min Reward\": f\"{np.min(r):.2f}\",\n",
    "        \"Max Reward\": f\"{np.max(r):.2f}\",\n",
    "        \"Success Rate\": f\"{(r >= 200).sum() / len(r) * 100:.1f}%\"\n",
    "    })\n",
    "\n",
    "all_r = np.concatenate([evaluation_results[s] for s in SEED_LIST])\n",
    "rows.append({\n",
    "    \"Seed\": \"Overall\",\n",
    "    \"Mean Reward\": f\"{np.mean(all_r):.2f}\",\n",
    "    \"Std Dev\": f\"{np.std(all_r):.2f}\",\n",
    "    \"Min Reward\": f\"{np.min(all_r):.2f}\",\n",
    "    \"Max Reward\": f\"{np.max(all_r):.2f}\",\n",
    "    \"Success Rate\": f\"{(all_r >= 200).sum() / len(all_r) * 100:.1f}%\"\n",
    "})\n",
    "\n",
    "print(f\"*** GA MULTI-SEED EVALUATION SUMMARY ***\")\n",
    "print(f\"Episodes per seed: {EVALUATION_EPISODES} | Total: {len(all_r)}\")\n",
    "print(pd.DataFrame(rows).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation Bar Chart\n",
    "\n",
    "n_seeds = len(SEED_LIST)\n",
    "x = np.arange(n_seeds)\n",
    "\n",
    "means = [np.mean(evaluation_results[s]) for s in SEED_LIST]\n",
    "stds = [np.std(evaluation_results[s]) for s in SEED_LIST]\n",
    "\n",
    "plt.figure(figsize=(max(8, 3 * n_seeds), 6))\n",
    "plt.bar(x, means, 0.6, yerr=stds, capsize=4, label='GA', alpha=0.8, color='tab:green')\n",
    "plt.axhline(y=200, color='red', linestyle='--', label='Solved Threshold (200)')\n",
    "plt.xticks(x, [str(s) for s in SEED_LIST])\n",
    "plt.title(f\"GA: Mean Reward per Seed ({EVALUATION_EPISODES} episodes each)\", fontsize=14)\n",
    "plt.xlabel(\"Seed\")\n",
    "plt.ylabel(\"Mean Reward\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation Convergence Plots (per seed)\n",
    "\n",
    "fig, axes = plt.subplots(1, len(SEED_LIST), figsize=(6 * len(SEED_LIST), 5), sharey=True)\n",
    "if len(SEED_LIST) == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for ax, seed in zip(axes, SEED_LIST):\n",
    "    rewards = evaluation_results[seed]\n",
    "    episodes = np.arange(1, len(rewards) + 1)\n",
    "    running_mean = np.cumsum(rewards) / episodes\n",
    "\n",
    "    ax.scatter(episodes, rewards, color='gray', alpha=0.4, s=20)\n",
    "    ax.plot(episodes, running_mean, color='blue', linewidth=2)\n",
    "    ax.axhline(y=200, color='red', linestyle='--')\n",
    "    ax.set_title(f\"Seed {seed}\")\n",
    "    ax.set_xlabel(\"Episode\")\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "axes[0].set_ylabel(\"Reward\")\n",
    "fig.suptitle(f\"GA Evaluation: {EVALUATION_EPISODES} Episodes per Seed\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GIF Visualization (one per seed, best genome)\n",
    "\n",
    "output_dir = os.path.join(NOTEBOOK_DIR, \"outputs_ga\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for seed in SEED_LIST:\n",
    "    print(f\"Generating GIF for GA seed {seed} (best genome)...\")\n",
    "\n",
    "    gif_path = os.path.join(output_dir, f\"ga_seed{seed}.gif\")\n",
    "    record_genome_gif(best_genomes[seed], seed, gif_path)\n",
    "\n",
    "    print(f\"  Saved: {gif_path}\")\n",
    "    display(Image(filename=gif_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter Table\n",
    "\n",
    "params = {\n",
    "    \"input_size\": INPUT_SIZE,\n",
    "    \"hidden1_size\": HIDDEN1_SIZE,\n",
    "    \"hidden2_size\": HIDDEN2_SIZE,\n",
    "    \"output_size\": OUTPUT_SIZE,\n",
    "    \"population_size\": POPULATION_SIZE,\n",
    "    \"mutation_rate\": MUTATION_RATE,\n",
    "    \"generations\": GENERATIONS,\n",
    "    \"eval_seeds_per_generation\": EVAL_SEEDS_PER_GEN,\n",
    "    \"elitism\": 3,\n",
    "    \"parent_selection\": \"top 20%\",\n",
    "    \"crossover\": \"uniform gene-wise\",\n",
    "    \"mutation\": \"Gaussian (clipped +/-0.1)\",\n",
    "    \"activation\": \"tanh (hidden), linear (output)\",\n",
    "    \"max_workers\": MAX_WORKERS,\n",
    "}\n",
    "\n",
    "rows = [{\"Parameter\": k, \"Value\": str(v)} for k, v in params.items()]\n",
    "\n",
    "print(\"*** GA Hyperparameters ***\")\n",
    "print(pd.DataFrame(rows).to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_taap_p2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
