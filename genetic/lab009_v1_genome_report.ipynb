{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neuroevolution (GA) Multi-Seed Report (Best Model Selection)\n",
    "\n",
    "This notebook loads the **best genome** from each training run (selected by the combined metric\n",
    "`mean_reward - std_reward` during training) and runs evaluation and visualization.\n",
    "\n",
    "No training is required — run lab009_v1_genome.ipynb first to generate the genome files.\n",
    "\n",
    "Models are loaded from timestamped run folders: `models/ga/{timestamp}/best_genome.npy`\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "import gymnasium as gym\n",
    "import imageio.v2 as imageio\n",
    "from IPython.display import Image, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add src/ to path\n",
    "SRC_DIR = os.path.join(os.path.dirname(os.path.abspath(\"__file__\")), \"src\")\n",
    "if SRC_DIR not in sys.path:\n",
    "    sys.path.insert(0, SRC_DIR)\n",
    "\n",
    "from src.evolution.neural_network import NeuralNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "\n",
    "SEED_LIST = [42, 123, 999]\n",
    "\n",
    "NOTEBOOK_DIR = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "GYMNASIUM_MODEL = \"LunarLander-v3\"\n",
    "\n",
    "WIND_ENABLED = False\n",
    "\n",
    "EVALUATION_EPISODES = 20\n",
    "\n",
    "TRAJECTORY_EPISODES = 3\n",
    "\n",
    "# Network architecture (must match training)\n",
    "INPUT_SIZE = 8\n",
    "HIDDEN1_SIZE = 10\n",
    "HIDDEN2_SIZE = 10\n",
    "OUTPUT_SIZE = 4\n",
    "\n",
    "# Session prefix — must match the final genome filenames from training\n",
    "# (e.g. lab009_ga_42.npy -> SESSION_PREFIX = \"lab009\")\n",
    "SESSION_PREFIX = \"lab009\"\n",
    "\n",
    "# LunarLander-v3 action labels\n",
    "ACTION_LABELS = [\"Do Nothing\", \"Fire Left\", \"Fire Main\", \"Fire Right\"]\n",
    "\n",
    "\n",
    "def discover_best_genomes(session_prefix):\n",
    "    \"\"\"\n",
    "    Scan models/ga/{timestamp}/ folders and return a dict:\n",
    "        {seed: {\"best\": path_to_best_genome, \"run_dir\": path, \"eval_log\": path_or_None}}\n",
    "    Only considers runs whose final genome filename starts with session_prefix.\n",
    "    \"\"\"\n",
    "    models_root = os.path.join(NOTEBOOK_DIR, \"../models\", \"ga\")\n",
    "    best_genomes = {}\n",
    "\n",
    "    if not os.path.isdir(models_root):\n",
    "        return best_genomes\n",
    "\n",
    "    for run_folder in sorted(glob.glob(os.path.join(models_root, \"????-??-??_??_??_??\"))):\n",
    "        best_genome_path = os.path.join(run_folder, \"best_genome.npy\")\n",
    "        if not os.path.isfile(best_genome_path):\n",
    "            continue\n",
    "\n",
    "        # Find the final genome file to extract session and seed\n",
    "        for f in os.listdir(run_folder):\n",
    "            if f.startswith(session_prefix) and f.endswith(\".npy\") and f != \"best_genome.npy\":\n",
    "                seed_str = f.replace(\".npy\", \"\").split(\"_\")[-1]\n",
    "                if seed_str.isdigit():\n",
    "                    seed_int = int(seed_str)\n",
    "                    if seed_int in SEED_LIST:\n",
    "                        eval_log_path = os.path.join(run_folder, \"eval_log\", \"evaluations.npz\")\n",
    "                        fitness_path = None\n",
    "                        for ff in os.listdir(run_folder):\n",
    "                            if ff.startswith(\"fitness_history\") and ff.endswith(\".npz\"):\n",
    "                                fitness_path = os.path.join(run_folder, ff)\n",
    "                                break\n",
    "                        best_genomes[seed_int] = {\n",
    "                            \"best\": best_genome_path,\n",
    "                            \"run_dir\": run_folder,\n",
    "                            \"eval_log\": eval_log_path if os.path.isfile(eval_log_path) else None,\n",
    "                            \"fitness_history\": fitness_path,\n",
    "                        }\n",
    "                break\n",
    "\n",
    "    return best_genomes\n",
    "\n",
    "\n",
    "# Discover best genomes for this session\n",
    "best_genome_paths = discover_best_genomes(SESSION_PREFIX)\n",
    "\n",
    "print(f\"Session: {SESSION_PREFIX}\")\n",
    "print(f\"Seeds: {SEED_LIST}\")\n",
    "print(f\"Wind enabled: {WIND_ENABLED}\")\n",
    "print(f\"Evaluation episodes per seed: {EVALUATION_EPISODES}\")\n",
    "print()\n",
    "print(\"Discovered best genomes:\")\n",
    "for seed in SEED_LIST:\n",
    "    info = best_genome_paths.get(seed)\n",
    "    if info:\n",
    "        print(f\"  Seed {seed}: {info['best']}\")\n",
    "        print(f\"    Eval log: {'Yes' if info['eval_log'] else 'No'}\")\n",
    "        print(f\"    Fitness history: {'Yes' if info['fitness_history'] else 'No'}\")\n",
    "    else:\n",
    "        print(f\"  Seed {seed}: NOT FOUND\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "\n",
    "def evaluate_genome_deterministic(genome, n_episodes, seed=None):\n",
    "    \"\"\"\n",
    "    Evaluate a genome deterministically over n_episodes.\n",
    "    No early termination. Returns list of per-episode rewards.\n",
    "    \"\"\"\n",
    "    nn = NeuralNetwork(INPUT_SIZE, HIDDEN1_SIZE, HIDDEN2_SIZE, OUTPUT_SIZE, genome)\n",
    "    env = gym.make(GYMNASIUM_MODEL, enable_wind=WIND_ENABLED)\n",
    "    rewards = []\n",
    "\n",
    "    for ep in range(n_episodes):\n",
    "        ep_seed = seed + ep if seed is not None else None\n",
    "        obs, _ = env.reset(seed=ep_seed)\n",
    "        total_reward = 0.0\n",
    "        done = False\n",
    "\n",
    "        while not done:\n",
    "            output = nn.forward(obs)\n",
    "            action = np.argmax(output)\n",
    "            obs, reward, terminated, truncated, _ = env.step(action)\n",
    "            done = terminated or truncated\n",
    "            total_reward += float(reward)\n",
    "\n",
    "        rewards.append(total_reward)\n",
    "\n",
    "    env.close()\n",
    "    return rewards\n",
    "\n",
    "\n",
    "def record_genome_gif(genome, seed, output_path):\n",
    "    nn = NeuralNetwork(INPUT_SIZE, HIDDEN1_SIZE, HIDDEN2_SIZE, OUTPUT_SIZE, genome)\n",
    "    env = gym.make(GYMNASIUM_MODEL, render_mode=\"rgb_array\", enable_wind=WIND_ENABLED)\n",
    "    obs, _ = env.reset(seed=seed)\n",
    "    frames = []\n",
    "    done = False\n",
    "\n",
    "    while not done:\n",
    "        frames.append(env.render())\n",
    "        output = nn.forward(obs)\n",
    "        action = np.argmax(output)\n",
    "        obs, reward, terminated, truncated, _ = env.step(action)\n",
    "        done = terminated or truncated\n",
    "\n",
    "    env.close()\n",
    "    imageio.mimsave(output_path, frames, fps=30, loop=0)\n",
    "    return output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best genomes and evaluate\n",
    "\n",
    "loaded_genomes = {}       # {seed: np.array}\n",
    "evaluation_results = {}   # {seed: np.array}\n",
    "\n",
    "for seed in SEED_LIST:\n",
    "    info = best_genome_paths.get(seed)\n",
    "    if info is None:\n",
    "        print(f\"SKIPPING seed {seed} - best genome not found\")\n",
    "        continue\n",
    "\n",
    "    print(f\"Loading and evaluating GA seed {seed} (best genome)...\")\n",
    "\n",
    "    genome = np.load(info[\"best\"])\n",
    "    loaded_genomes[seed] = genome\n",
    "\n",
    "    rewards = evaluate_genome_deterministic(genome, EVALUATION_EPISODES, seed=seed)\n",
    "    evaluation_results[seed] = np.array(rewards)\n",
    "\n",
    "    mean_r = np.mean(rewards)\n",
    "    std_r = np.std(rewards)\n",
    "    success = np.sum(np.array(rewards) >= 200) / len(rewards) * 100\n",
    "    print(f\"  Reward: {mean_r:.2f} +/- {std_r:.2f} | Success: {success:.0f}%\")\n",
    "\n",
    "print(f\"\\nEvaluation complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Fitness Curves (loaded from saved history)\n",
    "\n",
    "has_history = any(best_genome_paths.get(s, {}).get(\"fitness_history\") for s in SEED_LIST)\n",
    "\n",
    "if has_history:\n",
    "    fig, axes = plt.subplots(1, len(SEED_LIST), figsize=(6 * len(SEED_LIST), 5), sharey=True)\n",
    "    if len(SEED_LIST) == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    for ax, seed in zip(axes, SEED_LIST):\n",
    "        info = best_genome_paths.get(seed)\n",
    "        if info and info[\"fitness_history\"]:\n",
    "            data = np.load(info[\"fitness_history\"])\n",
    "            ax.plot(data[\"best\"], alpha=0.7, label=\"Best\")\n",
    "            ax.plot(data[\"avg\"], alpha=0.7, label=\"Average\")\n",
    "            ax.plot(data[\"worst\"], alpha=0.5, label=\"Worst\")\n",
    "            ax.axhline(y=200, color='red', linestyle='--', alpha=0.5)\n",
    "            ax.legend(fontsize=8)\n",
    "        ax.set_title(f\"Seed {seed}\")\n",
    "        ax.set_xlabel(\"Generation\")\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "    axes[0].set_ylabel(\"Fitness\")\n",
    "    fig.suptitle(\"GA - Training Fitness over Generations\", fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No fitness history files found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training: Rolling Best and Average Fitness (all seeds overlaid)\n",
    "\n",
    "if has_history:\n",
    "    seed_colors = list(plt.colormaps[\"tab10\"](range(10)))\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "    for i, seed in enumerate(SEED_LIST):\n",
    "        info = best_genome_paths.get(seed)\n",
    "        if info and info[\"fitness_history\"]:\n",
    "            data = np.load(info[\"fitness_history\"])\n",
    "            rolling_best = pd.Series(data[\"best\"]).rolling(50).mean()\n",
    "            rolling_avg = pd.Series(data[\"avg\"]).rolling(50).mean()\n",
    "            ax1.plot(rolling_best, color=seed_colors[i], linewidth=2, label=f\"Seed {seed}\")\n",
    "            ax2.plot(rolling_avg, color=seed_colors[i], linewidth=2, label=f\"Seed {seed}\")\n",
    "\n",
    "    ax1.axhline(y=200, color='red', linestyle='--', alpha=0.5, label='Solved (200)')\n",
    "    ax1.set_title(\"Rolling Best Fitness (window=50)\", fontsize=13)\n",
    "    ax1.set_xlabel(\"Generation\")\n",
    "    ax1.set_ylabel(\"Fitness\")\n",
    "    ax1.legend(fontsize=8)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "\n",
    "    ax2.axhline(y=200, color='red', linestyle='--', alpha=0.5, label='Solved (200)')\n",
    "    ax2.set_title(\"Rolling Average Fitness (window=50)\", fontsize=13)\n",
    "    ax2.set_xlabel(\"Generation\")\n",
    "    ax2.set_ylabel(\"Fitness\")\n",
    "    ax2.legend(fontsize=8)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "\n",
    "    fig.suptitle(\"GA Training: Fitness Progression across Seeds\", fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eval Score Progression during Training (from eval_log)\n",
    "\n",
    "has_eval_log = any(best_genome_paths.get(s, {}).get(\"eval_log\") for s in SEED_LIST)\n",
    "\n",
    "if has_eval_log:\n",
    "    fig, axes = plt.subplots(1, len(SEED_LIST), figsize=(6 * len(SEED_LIST), 5), sharey=True)\n",
    "    if len(SEED_LIST) == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    for ax, seed in zip(axes, SEED_LIST):\n",
    "        info = best_genome_paths.get(seed)\n",
    "        if info and info[\"eval_log\"]:\n",
    "            data = np.load(info[\"eval_log\"])\n",
    "            gens = data[\"generations\"]\n",
    "            means = data[\"means\"]\n",
    "            stds = data[\"stds\"]\n",
    "            scores = data[\"scores\"]\n",
    "\n",
    "            ax.plot(gens, means, color='blue', linewidth=2, label='Mean Reward')\n",
    "            ax.fill_between(gens, means - stds, means + stds, color='blue', alpha=0.15)\n",
    "            ax.plot(gens, scores, color='green', linewidth=1.5, linestyle='--', label='Score (mean-std)')\n",
    "            ax.axhline(y=200, color='red', linestyle='--', alpha=0.5)\n",
    "            ax.legend(fontsize=8)\n",
    "\n",
    "        ax.set_title(f\"Seed {seed}\")\n",
    "        ax.set_xlabel(\"Generation\")\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "    axes[0].set_ylabel(\"Reward\")\n",
    "    fig.suptitle(\"GA - Deterministic Eval Score during Training\", fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No eval log files found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Evaluation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation Summary Table\n",
    "\n",
    "rows = []\n",
    "for seed in SEED_LIST:\n",
    "    r = evaluation_results[seed]\n",
    "    rows.append({\n",
    "        \"Seed\": seed,\n",
    "        \"Mean Reward\": f\"{np.mean(r):.2f}\",\n",
    "        \"Std Dev\": f\"{np.std(r):.2f}\",\n",
    "        \"Min Reward\": f\"{np.min(r):.2f}\",\n",
    "        \"Max Reward\": f\"{np.max(r):.2f}\",\n",
    "        \"Success Rate\": f\"{(r >= 200).sum() / len(r) * 100:.1f}%\"\n",
    "    })\n",
    "\n",
    "all_r = np.concatenate([evaluation_results[s] for s in SEED_LIST])\n",
    "rows.append({\n",
    "    \"Seed\": \"Overall\",\n",
    "    \"Mean Reward\": f\"{np.mean(all_r):.2f}\",\n",
    "    \"Std Dev\": f\"{np.std(all_r):.2f}\",\n",
    "    \"Min Reward\": f\"{np.min(all_r):.2f}\",\n",
    "    \"Max Reward\": f\"{np.max(all_r):.2f}\",\n",
    "    \"Success Rate\": f\"{(all_r >= 200).sum() / len(all_r) * 100:.1f}%\"\n",
    "})\n",
    "\n",
    "print(f\"*** GA MULTI-SEED EVALUATION SUMMARY ***\")\n",
    "print(f\"Episodes per seed: {EVALUATION_EPISODES} | Total: {len(all_r)}\")\n",
    "print(pd.DataFrame(rows).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation Convergence Plots (per seed)\n",
    "\n",
    "fig, axes = plt.subplots(1, len(SEED_LIST), figsize=(6 * len(SEED_LIST), 5), sharey=True)\n",
    "if len(SEED_LIST) == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for ax, seed in zip(axes, SEED_LIST):\n",
    "    rewards = evaluation_results[seed]\n",
    "    episodes = np.arange(1, len(rewards) + 1)\n",
    "    running_mean = np.cumsum(rewards) / episodes\n",
    "    running_std = np.array([np.std(rewards[:i]) for i in episodes])\n",
    "\n",
    "    ax.scatter(episodes, rewards, color='gray', alpha=0.4, s=20, label='Episode Reward')\n",
    "    ax.plot(episodes, running_mean, color='blue', linewidth=2, label='Running Mean')\n",
    "    ax.fill_between(episodes, running_mean - running_std, running_mean + running_std,\n",
    "                    color='blue', alpha=0.15)\n",
    "    ax.axhline(y=200, color='red', linestyle='--')\n",
    "    ax.set_title(f\"Seed {seed}\")\n",
    "    ax.set_xlabel(\"Episode\")\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "axes[0].set_ylabel(\"Reward\")\n",
    "fig.suptitle(f\"GA Evaluation: {EVALUATION_EPISODES} Episodes per Seed\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation Bar Chart (mean reward per seed with error bars)\n",
    "\n",
    "seed_colors = list(plt.colormaps[\"tab10\"](range(10)))\n",
    "\n",
    "all_r = np.concatenate([evaluation_results[s] for s in SEED_LIST])\n",
    "means = [np.mean(evaluation_results[s]) for s in SEED_LIST]\n",
    "stds_vals = [np.std(evaluation_results[s]) for s in SEED_LIST]\n",
    "labels = [str(s) for s in SEED_LIST]\n",
    "\n",
    "plt.figure(figsize=(max(8, 3 * len(SEED_LIST)), 6))\n",
    "plt.bar(labels, means, yerr=stds_vals, capsize=5, color=seed_colors[:len(SEED_LIST)], alpha=0.8)\n",
    "plt.axhline(y=200, color='red', linestyle='--', label='Solved Threshold (200)')\n",
    "plt.axhline(y=float(np.mean(all_r)), color='blue', linestyle='-', linewidth=2,\n",
    "            label=f'Overall Mean ({np.mean(all_r):.1f})')\n",
    "\n",
    "plt.title(f\"GA Mean Reward per Seed ({EVALUATION_EPISODES} episodes each)\", fontsize=14)\n",
    "plt.xlabel(\"Seed\")\n",
    "plt.ylabel(\"Mean Reward\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reward Distribution Histograms (overlaid per seed)\n",
    "\n",
    "all_r = np.concatenate([evaluation_results[s] for s in SEED_LIST])\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "for i, seed in enumerate(SEED_LIST):\n",
    "    plt.hist(evaluation_results[seed], bins=10, alpha=0.5,\n",
    "             color=seed_colors[i], edgecolor='black', label=f\"Seed {seed}\")\n",
    "\n",
    "plt.axvline(x=float(np.mean(all_r)), color='blue', linestyle='-', linewidth=2,\n",
    "            label=f'Overall Mean ({np.mean(all_r):.1f})')\n",
    "plt.axvline(x=200, color='red', linestyle='--', label='Solved Threshold (200)')\n",
    "plt.title('GA Reward Distribution across Seeds')\n",
    "plt.xlabel('Reward')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box Plot per Seed\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "\n",
    "data = [evaluation_results[seed] for seed in SEED_LIST]\n",
    "bp = ax.boxplot(data, labels=[str(s) for s in SEED_LIST], patch_artist=True)\n",
    "for patch, color in zip(bp['boxes'], seed_colors[:len(SEED_LIST)]):\n",
    "    patch.set_facecolor(color)\n",
    "    patch.set_alpha(0.6)\n",
    "\n",
    "ax.axhline(y=200, color='red', linestyle='--', label='Solved Threshold (200)')\n",
    "ax.set_title(f\"GA: Reward Distribution per Seed ({EVALUATION_EPISODES} episodes each)\", fontsize=14)\n",
    "ax.set_xlabel(\"Seed\")\n",
    "ax.set_ylabel(\"Reward\")\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Baseline Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Agent Baseline Evaluation\n",
    "\n",
    "random_results = {}\n",
    "\n",
    "for seed in SEED_LIST:\n",
    "    print(f\"Running random agent with seed {seed}...\")\n",
    "    env = gym.make(GYMNASIUM_MODEL, enable_wind=WIND_ENABLED)\n",
    "    env.action_space.seed(seed)\n",
    "    episode_rewards = []\n",
    "\n",
    "    for ep in range(EVALUATION_EPISODES):\n",
    "        obs, info = env.reset(seed=seed + ep)\n",
    "        total_reward = 0.0\n",
    "        done = False\n",
    "\n",
    "        while not done:\n",
    "            action = env.action_space.sample()\n",
    "            obs, reward, terminated, truncated, info = env.step(action)\n",
    "            total_reward += float(reward)\n",
    "            done = terminated or truncated\n",
    "\n",
    "        episode_rewards.append(total_reward)\n",
    "\n",
    "    random_results[seed] = np.array(episode_rewards)\n",
    "    env.close()\n",
    "\n",
    "print(\"Random baseline evaluation complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline Comparison: Table + Chart\n",
    "\n",
    "all_ga = np.concatenate([evaluation_results[s] for s in SEED_LIST])\n",
    "all_random = np.concatenate([random_results[s] for s in SEED_LIST])\n",
    "\n",
    "rows = [\n",
    "    {\n",
    "        \"Agent\": \"Random\",\n",
    "        \"Mean Reward\": f\"{np.mean(all_random):.2f}\",\n",
    "        \"Std Dev\": f\"{np.std(all_random):.2f}\",\n",
    "        \"Min\": f\"{np.min(all_random):.2f}\",\n",
    "        \"Max\": f\"{np.max(all_random):.2f}\",\n",
    "        \"Success Rate\": f\"{(all_random >= 200).sum() / len(all_random) * 100:.1f}%\"\n",
    "    },\n",
    "    {\n",
    "        \"Agent\": \"GA\",\n",
    "        \"Mean Reward\": f\"{np.mean(all_ga):.2f}\",\n",
    "        \"Std Dev\": f\"{np.std(all_ga):.2f}\",\n",
    "        \"Min\": f\"{np.min(all_ga):.2f}\",\n",
    "        \"Max\": f\"{np.max(all_ga):.2f}\",\n",
    "        \"Success Rate\": f\"{(all_ga >= 200).sum() / len(all_ga) * 100:.1f}%\"\n",
    "    },\n",
    "    {\n",
    "        \"Agent\": \"Human (ref)\",\n",
    "        \"Mean Reward\": \"~200-300\",\n",
    "        \"Std Dev\": \"-\",\n",
    "        \"Min\": \"-\",\n",
    "        \"Max\": \"-\",\n",
    "        \"Success Rate\": \"~100%\"\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"*** BASELINE COMPARISON ***\")\n",
    "print(pd.DataFrame(rows).to_string(index=False))\n",
    "print()\n",
    "\n",
    "# Bar chart\n",
    "agent_labels = [\"Random\", \"GA\"]\n",
    "agent_means = [np.mean(all_random), np.mean(all_ga)]\n",
    "agent_stds = [np.std(all_random), np.std(all_ga)]\n",
    "bar_colors = [\"gray\", \"tab:green\"]\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "bars = plt.bar(agent_labels, agent_means, yerr=agent_stds, capsize=6,\n",
    "               color=bar_colors, alpha=0.8)\n",
    "plt.axhline(y=200, color='red', linestyle='--', label='Solved Threshold (200)')\n",
    "\n",
    "for bar, mean in zip(bars, agent_means):\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 5,\n",
    "             f'{mean:.1f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.title(f\"Baseline Comparison: Random vs GA ({EVALUATION_EPISODES * len(SEED_LIST)} episodes each)\", fontsize=14)\n",
    "plt.ylabel(\"Mean Reward\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Statistical Significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical Significance: GA vs Random (Mann-Whitney U + Chi-squared)\n",
    "\n",
    "# --- Reward comparison (Mann-Whitney U) ---\n",
    "mwu_result = stats.mannwhitneyu(all_ga, all_random, alternative='two-sided')\n",
    "stat_reward = float(mwu_result.statistic)\n",
    "p_reward = float(mwu_result.pvalue)\n",
    "\n",
    "# --- Success rate comparison (Chi-squared) ---\n",
    "ga_successes = int((all_ga >= 200).sum())\n",
    "random_successes = int((all_random >= 200).sum())\n",
    "ga_total = len(all_ga)\n",
    "random_total = len(all_random)\n",
    "\n",
    "contingency = np.array([\n",
    "    [ga_successes, ga_total - ga_successes],\n",
    "    [random_successes, random_total - random_successes]\n",
    "])\n",
    "\n",
    "if np.all(contingency.sum(axis=0) > 0) and np.all(contingency.sum(axis=1) > 0):\n",
    "    chi2_result = stats.chi2_contingency(contingency)\n",
    "    chi2 = float(chi2_result[0])\n",
    "    p_success = float(chi2_result[1])\n",
    "    chi2_valid = True\n",
    "else:\n",
    "    chi2, p_success = 0.0, 1.0\n",
    "    chi2_valid = False\n",
    "\n",
    "# --- Results table ---\n",
    "chi2_note = \"\" if chi2_valid else \" (skipped: zero row/col)\"\n",
    "rows = [\n",
    "    {\n",
    "        \"Metric\": \"Mean Reward\",\n",
    "        \"GA Value\": f\"{np.mean(all_ga):.2f}\",\n",
    "        \"Random Value\": f\"{np.mean(all_random):.2f}\",\n",
    "        \"Test\": \"Mann-Whitney U\",\n",
    "        \"Statistic\": f\"{stat_reward:.1f}\",\n",
    "        \"p-value\": f\"{p_reward:.4f}\",\n",
    "        \"Significant (p<0.05)\": \"Yes\" if p_reward < 0.05 else \"No\"\n",
    "    },\n",
    "    {\n",
    "        \"Metric\": \"Success Rate (>=200)\",\n",
    "        \"GA Value\": f\"{ga_successes/ga_total*100:.1f}%\",\n",
    "        \"Random Value\": f\"{random_successes/random_total*100:.1f}%\",\n",
    "        \"Test\": f\"Chi-squared{chi2_note}\",\n",
    "        \"Statistic\": f\"{chi2:.2f}\",\n",
    "        \"p-value\": f\"{p_success:.4f}\",\n",
    "        \"Significant (p<0.05)\": \"Yes\" if (chi2_valid and p_success < 0.05) else \"No\"\n",
    "    },\n",
    "]\n",
    "\n",
    "print(\"*** STATISTICAL SIGNIFICANCE TESTS: GA vs Random ***\")\n",
    "print(f\"Sample size per agent: {ga_total} episodes ({EVALUATION_EPISODES} episodes x {len(SEED_LIST)} seeds)\")\n",
    "print()\n",
    "print(pd.DataFrame(rows).to_string(index=False))\n",
    "print()\n",
    "if p_reward < 0.05:\n",
    "    print(f\"The reward difference between GA and Random is statistically significant (p={p_reward:.4f}).\")\n",
    "else:\n",
    "    print(f\"No statistically significant reward difference between GA and Random (p={p_reward:.4f}).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Agent Behavior Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect per-step data: actions and trajectories\n",
    "\n",
    "action_counts = np.zeros(len(ACTION_LABELS), dtype=int)\n",
    "trajectory_data = []  # list of (x_positions, y_positions)\n",
    "\n",
    "for seed in SEED_LIST:\n",
    "    genome = loaded_genomes[seed]\n",
    "    nn = NeuralNetwork(INPUT_SIZE, HIDDEN1_SIZE, HIDDEN2_SIZE, OUTPUT_SIZE, genome)\n",
    "    env = gym.make(GYMNASIUM_MODEL, enable_wind=WIND_ENABLED)\n",
    "\n",
    "    for ep in range(EVALUATION_EPISODES):\n",
    "        obs, info = env.reset(seed=seed + ep)\n",
    "        done = False\n",
    "        x_pos, y_pos = [obs[0]], [obs[1]]\n",
    "\n",
    "        while not done:\n",
    "            output = nn.forward(obs)\n",
    "            action = int(np.argmax(output))\n",
    "            action_counts[action] += 1\n",
    "\n",
    "            obs, reward, terminated, truncated, info = env.step(action)\n",
    "            done = terminated or truncated\n",
    "            x_pos.append(obs[0])\n",
    "            y_pos.append(obs[1])\n",
    "\n",
    "        # Keep trajectory for the first TRAJECTORY_EPISODES episodes of the first seed\n",
    "        if seed == SEED_LIST[0] and ep < TRAJECTORY_EPISODES:\n",
    "            trajectory_data.append((np.array(x_pos), np.array(y_pos)))\n",
    "\n",
    "    env.close()\n",
    "\n",
    "total_actions = action_counts.sum()\n",
    "print(f\"GA: {total_actions:,} total actions collected across {EVALUATION_EPISODES * len(SEED_LIST)} episodes\")\n",
    "print(\"\\nBehavior data collection complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Action Distribution\n",
    "\n",
    "n_actions = len(ACTION_LABELS)\n",
    "x = np.arange(n_actions)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Absolute counts\n",
    "ax1.bar(x, action_counts, color='tab:green', alpha=0.8)\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(ACTION_LABELS, rotation=15)\n",
    "ax1.set_title(\"Action Counts (Absolute)\", fontsize=13)\n",
    "ax1.set_ylabel(\"Count\")\n",
    "ax1.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Percentage distribution\n",
    "pcts = action_counts / action_counts.sum() * 100\n",
    "bars = ax2.bar(x, pcts, color='tab:green', alpha=0.8)\n",
    "for bar, pct in zip(bars, pcts):\n",
    "    ax2.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.5,\n",
    "             f'{pct:.1f}%', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "ax2.set_xticks(x)\n",
    "ax2.set_xticklabels(ACTION_LABELS, rotation=15)\n",
    "ax2.set_title(\"Action Distribution (Percentage)\", fontsize=13)\n",
    "ax2.set_ylabel(\"Percentage (%)\")\n",
    "ax2.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "fig.suptitle(f\"GA: Action Distribution ({EVALUATION_EPISODES * len(SEED_LIST)} episodes)\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trajectory Plots: x-y paths of the lander\n",
    "\n",
    "traj_colors = list(plt.colormaps[\"Set2\"](range(8)))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "\n",
    "for i, (x_pos, y_pos) in enumerate(trajectory_data):\n",
    "    ax.plot(x_pos, y_pos, color=traj_colors[i], linewidth=1.5, alpha=0.8,\n",
    "            label=f\"Episode {i+1}\")\n",
    "    ax.scatter(x_pos[0], y_pos[0], color=traj_colors[i], marker='o', s=60, zorder=5)\n",
    "    ax.scatter(x_pos[-1], y_pos[-1], color=traj_colors[i], marker='x', s=80, zorder=5)\n",
    "\n",
    "ax.axhline(y=0, color='black', linestyle='-', linewidth=0.5, alpha=0.3)\n",
    "ax.axvline(x=0, color='black', linestyle='-', linewidth=0.5, alpha=0.3)\n",
    "ax.scatter(0, 0, color='red', marker='^', s=120, zorder=10, label='Landing Pad')\n",
    "\n",
    "ax.set_title(f\"GA Lander Trajectories (seed {SEED_LIST[0]}, {TRAJECTORY_EPISODES} episodes)\", fontsize=14)\n",
    "ax.set_xlabel(\"X Position\")\n",
    "ax.set_ylabel(\"Y Position\")\n",
    "ax.legend(fontsize=9)\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## GIF Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GIF Visualizations (one per seed, best genome)\n",
    "\n",
    "output_dir = os.path.join(NOTEBOOK_DIR, \"outputs_ga\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for seed in SEED_LIST:\n",
    "    if seed not in loaded_genomes:\n",
    "        print(f\"SKIPPING GIF for seed {seed} - genome not loaded\")\n",
    "        continue\n",
    "\n",
    "    print(f\"Generating GIF for GA seed {seed} (best genome)...\")\n",
    "\n",
    "    gif_path = os.path.join(output_dir, f\"ga_seed{seed}.gif\")\n",
    "    record_genome_gif(loaded_genomes[seed], seed, gif_path)\n",
    "\n",
    "    print(f\"  Saved: {gif_path}\")\n",
    "    display(Image(filename=gif_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Appendix: Experimental Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment Details\n",
    "\n",
    "| Property | Value |\n",
    "|---|---|\n",
    "| Environment | `LunarLander-v3` (Gymnasium) |\n",
    "| Observation Space | `Box(8,)` — continuous 8-dimensional vector |\n",
    "| Action Space | `Discrete(4)` — do nothing, fire left, fire main, fire right |\n",
    "| Solved Threshold | Mean reward >= 200 over 100 consecutive episodes |\n",
    "| Wind | Disabled (`enable_wind=False`) |\n",
    "\n",
    "**Observation vector:** `[x, y, vx, vy, angle, angular_velocity, left_leg_contact, right_leg_contact]`\n",
    "\n",
    "**Reward structure:**\n",
    "- Moving toward the landing pad: positive\n",
    "- Moving away: negative\n",
    "- Crash: -100\n",
    "- Successful landing: +100\n",
    "- Each leg ground contact: +10\n",
    "- Firing main engine: -0.3 per frame\n",
    "- Firing side engine: -0.03 per frame\n",
    "\n",
    "**Termination rules:**\n",
    "- **Terminated (success):** The lander comes to rest on the ground with both legs in contact, near-zero velocity\n",
    "- **Terminated (crash):** The lander body contacts the ground, or the lander moves outside the viewport boundaries\n",
    "- **Truncated (timeout):** The episode exceeds 1000 timesteps without termination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment inspection\n",
    "\n",
    "env_tmp = gym.make(GYMNASIUM_MODEL, enable_wind=WIND_ENABLED)\n",
    "print(f\"Environment: {GYMNASIUM_MODEL}\")\n",
    "print(f\"Observation space: {env_tmp.observation_space}\")\n",
    "print(f\"Action space: {env_tmp.action_space}\")\n",
    "print(f\"Wind enabled: {WIND_ENABLED}\")\n",
    "\n",
    "obs, info = env_tmp.reset(seed=42)\n",
    "print(f\"\\nSample observation: {obs}\")\n",
    "print(f\"Observation labels: [x, y, vx, vy, angle, angular_vel, left_leg, right_leg]\")\n",
    "env_tmp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System and library versions\n",
    "\n",
    "print(f\"Python: {sys.version.split()[0]}\")\n",
    "print(f\"Gymnasium: {gym.__version__}\")\n",
    "print(f\"NumPy: {np.__version__}\")\n",
    "print(f\"Network: {INPUT_SIZE} -> {HIDDEN1_SIZE} -> {HIDDEN2_SIZE} -> {OUTPUT_SIZE}\")\n",
    "print(f\"Activation: tanh (hidden), linear (output)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_taap_p2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbformat_minor": 4,
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
