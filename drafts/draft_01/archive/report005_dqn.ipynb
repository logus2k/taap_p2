{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# DQN Multi-Seed Report\n",
    "\n",
    "This notebook loads pre-trained models (one per seed) and runs evaluation and visualization.\n",
    "No training is required â€” run lab005_dqn.ipynb first to generate the model files.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import gymnasium as gym\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "\n",
    "import imageio\n",
    "from IPython.display import Image, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "\n",
    "SEED_LIST = [42, 123, 3407]\n",
    "\n",
    "SELECTED_ALGORITHM = \"dqn\"\n",
    "ALGORITHM_CLASS = DQN\n",
    "\n",
    "NOTEBOOK_DIR = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "MODELS_DIR = os.path.join(NOTEBOOK_DIR, \"../../../models\", SELECTED_ALGORITHM)\n",
    "OUTPUT_DIR = os.path.join(NOTEBOOK_DIR, \"outputs_\" + SELECTED_ALGORITHM)\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "GYMNASIUM_MODEL = \"LunarLander-v3\"\n",
    "\n",
    "WIND_ENABLED = False\n",
    "\n",
    "EVALUATION_EPISODES = 20\n",
    "\n",
    "DEVICE = \"cpu\"\n",
    "\n",
    "print(f\"Algorithm: {SELECTED_ALGORITHM.upper()}\")\n",
    "print(f\"Seeds: {SEED_LIST}\")\n",
    "print(f\"Wind enabled: {WIND_ENABLED}\")\n",
    "print(f\"Evaluation episodes per seed: {EVALUATION_EPISODES}\")\n",
    "print(f\"Models directory: {MODELS_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all models and evaluate\n",
    "\n",
    "evaluation_results = {}\n",
    "\n",
    "for seed in SEED_LIST:\n",
    "    print(f\"Loading and evaluating model for seed {seed}...\")\n",
    "\n",
    "    load_path = os.path.join(MODELS_DIR, f\"lab005_{SELECTED_ALGORITHM}_{seed}\")\n",
    "\n",
    "    def make_env(s=seed):\n",
    "        env = gym.make(GYMNASIUM_MODEL, render_mode=\"rgb_array\", enable_wind=WIND_ENABLED)\n",
    "        env.reset(seed=s)\n",
    "        return env\n",
    "\n",
    "    model = ALGORITHM_CLASS.load(load_path, env=DummyVecEnv([make_env]), device=DEVICE)\n",
    "\n",
    "    eval_env = Monitor(gym.make(GYMNASIUM_MODEL, enable_wind=WIND_ENABLED))\n",
    "    eval_env.reset(seed=seed)\n",
    "\n",
    "    rewards, _ = evaluate_policy(\n",
    "        model,\n",
    "        eval_env,\n",
    "        n_eval_episodes=EVALUATION_EPISODES,\n",
    "        deterministic=True,\n",
    "        return_episode_rewards=True\n",
    "    )\n",
    "\n",
    "    evaluation_results[seed] = np.array(rewards)\n",
    "    eval_env.close()\n",
    "\n",
    "print(f\"\\nEvaluation complete for all {len(SEED_LIST)} seeds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation Summary Table\n",
    "\n",
    "rows = []\n",
    "for seed in SEED_LIST:\n",
    "    r = evaluation_results[seed]\n",
    "    rows.append({\n",
    "        \"Seed\": seed,\n",
    "        \"Mean Reward\": f\"{np.mean(r):.2f}\",\n",
    "        \"Std Dev\": f\"{np.std(r):.2f}\",\n",
    "        \"Min Reward\": f\"{np.min(r):.2f}\",\n",
    "        \"Max Reward\": f\"{np.max(r):.2f}\",\n",
    "        \"Success Rate\": f\"{(r >= 200).sum() / len(r) * 100:.1f}%\"\n",
    "    })\n",
    "\n",
    "all_rewards = np.concatenate(list(evaluation_results.values()))\n",
    "rows.append({\n",
    "    \"Seed\": \"Overall\",\n",
    "    \"Mean Reward\": f\"{np.mean(all_rewards):.2f}\",\n",
    "    \"Std Dev\": f\"{np.std(all_rewards):.2f}\",\n",
    "    \"Min Reward\": f\"{np.min(all_rewards):.2f}\",\n",
    "    \"Max Reward\": f\"{np.max(all_rewards):.2f}\",\n",
    "    \"Success Rate\": f\"{(all_rewards >= 200).sum() / len(all_rewards) * 100:.1f}%\"\n",
    "})\n",
    "\n",
    "df_summary = pd.DataFrame(rows)\n",
    "print(f\"*** {SELECTED_ALGORITHM.upper()} MULTI-SEED EVALUATION SUMMARY ***\")\n",
    "print(f\"Episodes per seed: {EVALUATION_EPISODES}\")\n",
    "print(f\"Total episodes: {len(all_rewards)}\")\n",
    "print()\n",
    "print(df_summary.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per-Seed: Evaluation Convergence Plots\n",
    "\n",
    "fig, axes = plt.subplots(1, len(SEED_LIST), figsize=(6 * len(SEED_LIST), 5), sharey=True)\n",
    "if len(SEED_LIST) == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for ax, seed in zip(axes, SEED_LIST):\n",
    "    rewards = evaluation_results[seed]\n",
    "    episodes = np.arange(1, len(rewards) + 1)\n",
    "    running_mean = np.cumsum(rewards) / episodes\n",
    "    running_std = np.array([np.std(rewards[:i]) for i in episodes])\n",
    "\n",
    "    ax.scatter(episodes, rewards, color='gray', alpha=0.4, s=20, label='Episode Reward')\n",
    "    ax.plot(episodes, running_mean, color='blue', linewidth=2, label='Running Mean')\n",
    "    ax.fill_between(episodes, running_mean - running_std, running_mean + running_std,\n",
    "                    color='blue', alpha=0.15)\n",
    "    ax.axhline(y=200, color='red', linestyle='--')\n",
    "    ax.set_title(f\"Seed {seed}\")\n",
    "    ax.set_xlabel(\"Episode\")\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "axes[0].set_ylabel(\"Reward\")\n",
    "fig.suptitle(f\"{SELECTED_ALGORITHM.upper()} Evaluation: {EVALUATION_EPISODES} Episodes per Seed\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregated: Evaluation Bar Chart (mean reward per seed with error bars)\n",
    "\n",
    "colors = plt.cm.tab10.colors\n",
    "\n",
    "means = [np.mean(evaluation_results[s]) for s in SEED_LIST]\n",
    "stds = [np.std(evaluation_results[s]) for s in SEED_LIST]\n",
    "labels = [str(s) for s in SEED_LIST]\n",
    "\n",
    "plt.figure(figsize=(max(8, 3 * len(SEED_LIST)), 6))\n",
    "bars = plt.bar(labels, means, yerr=stds, capsize=5, color=colors[:len(SEED_LIST)], alpha=0.8)\n",
    "plt.axhline(y=200, color='red', linestyle='--', label='Solved Threshold (200)')\n",
    "plt.axhline(y=np.mean(all_rewards), color='blue', linestyle='-', linewidth=2,\n",
    "            label=f'Overall Mean ({np.mean(all_rewards):.1f})')\n",
    "\n",
    "plt.title(f\"{SELECTED_ALGORITHM.upper()} Mean Reward per Seed ({EVALUATION_EPISODES} episodes each)\", fontsize=14)\n",
    "plt.xlabel(\"Seed\")\n",
    "plt.ylabel(\"Mean Reward\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reward Distribution Histograms (overlaid)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "for i, seed in enumerate(SEED_LIST):\n",
    "    plt.hist(evaluation_results[seed], bins=10, alpha=0.5, color=colors[i],\n",
    "             edgecolor='black', label=f\"Seed {seed}\")\n",
    "\n",
    "plt.axvline(x=200, color='red', linestyle='--', label='Solved Threshold (200)')\n",
    "plt.axvline(x=np.mean(all_rewards), color='blue', linestyle='-', linewidth=2,\n",
    "            label=f'Overall Mean ({np.mean(all_rewards):.1f})')\n",
    "plt.title('Reward Distribution across Seeds')\n",
    "plt.xlabel('Reward')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GIF Visualizations (one per seed)\n",
    "\n",
    "for seed in SEED_LIST:\n",
    "    print(f\"Generating GIF for seed {seed}...\")\n",
    "\n",
    "    load_path = os.path.join(MODELS_DIR, f\"lab005_{SELECTED_ALGORITHM}_{seed}\")\n",
    "\n",
    "    def make_vis_env(s=seed):\n",
    "        env = gym.make(GYMNASIUM_MODEL, render_mode=\"rgb_array\", enable_wind=WIND_ENABLED)\n",
    "        env.reset(seed=s)\n",
    "        return env\n",
    "\n",
    "    vis_model = ALGORITHM_CLASS.load(load_path, env=DummyVecEnv([make_vis_env]), device=DEVICE)\n",
    "\n",
    "    vis_env = gym.make(GYMNASIUM_MODEL, render_mode=\"rgb_array\", enable_wind=WIND_ENABLED)\n",
    "    frames = []\n",
    "    obs, info = vis_env.reset(seed=seed)\n",
    "    done = False\n",
    "\n",
    "    while not done:\n",
    "        action, _ = vis_model.predict(obs, deterministic=True)\n",
    "        obs, reward, terminated, truncated, info = vis_env.step(action)\n",
    "        done = terminated or truncated\n",
    "        frames.append(vis_env.render())\n",
    "\n",
    "    vis_env.close()\n",
    "\n",
    "    gif_path = os.path.join(OUTPUT_DIR, f\"{SELECTED_ALGORITHM}_seed{seed}.gif\")\n",
    "    imageio.mimsave(gif_path, frames, fps=30)\n",
    "    print(f\"  Saved: {gif_path}\")\n",
    "    display(Image(filename=gif_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Additional analysis cells can go below"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}